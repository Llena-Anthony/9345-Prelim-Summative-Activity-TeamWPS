{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DS55 — Region × Sector Structural Analysis\n",
    "**Member Assigned:** MARTIN, Randy Jr.\n",
    "**Task Name:** Region × Sector Structural Analysis ## Task Description Examine the structural composition of regional economies by comparing sectoral contributions across regions. Classify regions according to whether they are agriculture-heavy, industry-heavy, or service-heavy. ## Expected Outputs - Region × Sector summary table - Classification of regional economic structures - Structural comparison visualization (stacked bar or heatmap) - Interpretation of regional specialization patterns ## Dataset: SECTORAL ECONOMIC STRUCTURE (Sector Level)"
   ],
   "id": "3540b2d6c8f6763e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS55 Region x Sector Structural Analysis\n",
    "Compares sectoral composition across regions, computes sector shares, classifies each region by dominant sector, and saves structural comparison tables and figures.\n"
   ],
   "id": "7be81525f6e32088"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Robust BASE_DIR resolution for script and notebook contexts.\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parents[2]\n",
    "except NameError:\n",
    "    cwd = Path.cwd().resolve()\n",
    "    if (cwd / '03_Cleaned_Data').exists():\n",
    "        BASE_DIR = cwd\n",
    "    elif (cwd.parent / '03_Cleaned_Data').exists():\n",
    "        BASE_DIR = cwd.parent\n",
    "    else:\n",
    "        BASE_DIR = cwd.parents[1] if len(cwd.parents) > 1 else cwd\n",
    "\n",
    "CLEAN_DIR = BASE_DIR / '03_Cleaned_Data'\n",
    "OUT_TABLES = BASE_DIR / 'outputs' / 'tables'\n",
    "OUT_FIGS = BASE_DIR / 'outputs' / 'figures'\n",
    "\n",
    "OUT_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'BASE_DIR: {BASE_DIR}')\n",
    "print(f'CLEAN_DIR: {CLEAN_DIR}')\n",
    "print(f'OUT_TABLES: {OUT_TABLES}')\n",
    "print(f'OUT_FIGS: {OUT_FIGS}')\n"
   ],
   "id": "ded0bb81889118c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset 3 (primary input)\n",
    "file_d3 = CLEAN_DIR / 'Dataset 3 Region_Sector_Structure (CLEANED).csv'\n",
    "df = pd.read_csv(file_d3)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "print(df.head())\n",
    "print('\\nUnique regions:', df['Region'].nunique())\n",
    "print('Unique sectors:', sorted(df['Main_Sector'].dropna().unique().tolist()))\n",
    "print('Year range:', int(df['Year'].min()), 'to', int(df['Year'].max()))\n",
    "print('Price types:', sorted(df['Price_Type'].dropna().unique().tolist()))\n"
   ],
   "id": "b27d6c79f6c7b996"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning / standardization\n",
    "expected_sectors = [\n",
    "    'Agriculture, forestry, and fishing',\n",
    "    'Industry',\n",
    "    'Services'\n",
    "]\n",
    "\n",
    "df['Main_Sector'] = (\n",
    "    df['Main_Sector']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    ")\n",
    "\n",
    "df['Sector_GRDP'] = pd.to_numeric(df['Sector_GRDP'], errors='coerce')\n",
    "\n",
    "before_rows = len(df)\n",
    "df = df.dropna(subset=['Sector_GRDP']).copy()\n",
    "after_numeric_rows = len(df)\n",
    "\n",
    "# Keep only expected sectors for structural comparison\n",
    "invalid_sector_rows = (~df['Main_Sector'].isin(expected_sectors)).sum()\n",
    "df = df[df['Main_Sector'].isin(expected_sectors)].copy()\n",
    "after_sector_rows = len(df)\n",
    "\n",
    "print(f'Rows before numeric cleaning: {before_rows}')\n",
    "print(f'Rows after dropping non-numeric Sector_GRDP: {after_numeric_rows}')\n",
    "print(f'Rows removed for non-target sectors: {invalid_sector_rows}')\n",
    "print(f'Rows in final cleaned scope: {after_sector_rows}')\n",
    "print('Sectors retained:', sorted(df['Main_Sector'].unique().tolist()))\n"
   ],
   "id": "bf85d427bc9346df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_tag(value):\n",
    "    text = str(value).strip()\n",
    "    text = ''.join(ch if ch.isalnum() else '_' for ch in text)\n",
    "    while '__' in text:\n",
    "        text = text.replace('__', '_')\n",
    "    return text.strip('_')\n",
    "\n",
    "all_outputs = []\n",
    "interpretation_rows = []\n",
    "\n",
    "price_types = sorted(df['Price_Type'].dropna().unique().tolist())\n",
    "print('Price types to analyze:', price_types)\n"
   ],
   "id": "460c44921603814e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region x Sector analysis by Price_Type (latest year per price type)\n",
    "for pt in price_types:\n",
    "    latest_year = int(df.loc[df['Price_Type'] == pt, 'Year'].max())\n",
    "    df_scope = df[(df['Price_Type'] == pt) & (df['Year'] == latest_year)].copy()\n",
    "\n",
    "    print(f'\\nAnalyzing Price_Type={pt} | latest_year={latest_year} | rows={len(df_scope)}')\n",
    "\n",
    "    # Expected Output #1: Region x Sector pivot table\n",
    "    pivot = pd.pivot_table(\n",
    "        df_scope,\n",
    "        index='Region',\n",
    "        columns='Main_Sector',\n",
    "        values='Sector_GRDP',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0.0\n",
    "    )\n",
    "\n",
    "    for sector in expected_sectors:\n",
    "        if sector not in pivot.columns:\n",
    "            pivot[sector] = 0.0\n",
    "\n",
    "    pivot = pivot[expected_sectors].sort_index()\n",
    "    pivot['Total'] = pivot.sum(axis=1)\n",
    "\n",
    "    shares = pivot.copy()\n",
    "    shares['Share_Agri'] = np.where(\n",
    "        shares['Total'] != 0,\n",
    "        shares['Agriculture, forestry, and fishing'] / shares['Total'],\n",
    "        np.nan\n",
    "    )\n",
    "    shares['Share_Industry'] = np.where(\n",
    "        shares['Total'] != 0,\n",
    "        shares['Industry'] / shares['Total'],\n",
    "        np.nan\n",
    "    )\n",
    "    shares['Share_Services'] = np.where(\n",
    "        shares['Total'] != 0,\n",
    "        shares['Services'] / shares['Total'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    shares_table = shares[['Share_Agri', 'Share_Industry', 'Share_Services']].copy()\n",
    "\n",
    "    # Expected Output #2: Classification table\n",
    "    class_df = shares_table.copy().reset_index()\n",
    "    class_df['Year'] = latest_year\n",
    "    class_df['Price_Type'] = pt\n",
    "\n",
    "    share_cols = ['Share_Agri', 'Share_Industry', 'Share_Services']\n",
    "    share_to_sector = {\n",
    "        'Share_Agri': 'Agriculture',\n",
    "        'Share_Industry': 'Industry',\n",
    "        'Share_Services': 'Services'\n",
    "    }\n",
    "\n",
    "    max_col = class_df[share_cols].idxmax(axis=1)\n",
    "    class_df['Dominant_Sector'] = max_col.map(share_to_sector)\n",
    "    class_df['Classification'] = class_df['Dominant_Sector'] + '-heavy'\n",
    "    class_df['Max_Share'] = class_df[share_cols].max(axis=1)\n",
    "\n",
    "    def second_max(row):\n",
    "        vals = row[share_cols].to_numpy(dtype=float)\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "        if vals.size < 2:\n",
    "            return np.nan\n",
    "        return np.sort(vals)[-2]\n",
    "\n",
    "    class_df['Second_Max_Share'] = class_df.apply(second_max, axis=1)\n",
    "    class_df['Dominance_Gap'] = class_df['Max_Share'] - class_df['Second_Max_Share']\n",
    "\n",
    "    class_df = class_df[\n",
    "        [\n",
    "            'Region', 'Year', 'Price_Type',\n",
    "            'Share_Agri', 'Share_Industry', 'Share_Services',\n",
    "            'Dominant_Sector', 'Classification', 'Max_Share', 'Dominance_Gap'\n",
    "        ]\n",
    "    ].sort_values(['Dominant_Sector', 'Max_Share', 'Region'], ascending=[True, False, True]).reset_index(drop=True)\n",
    "\n",
    "    # Quality check: share sums should be ~1.0\n",
    "    share_sum = shares_table.sum(axis=1)\n",
    "    invalid_mask = ~np.isclose(share_sum, 1.0, atol=1e-6, equal_nan=False)\n",
    "    failing_regions = shares_table.index[invalid_mask].tolist()\n",
    "\n",
    "    if failing_regions:\n",
    "        print(f'Share-sum check FAILED for {len(failing_regions)} region(s): {failing_regions}')\n",
    "    else:\n",
    "        print('Share-sum check passed for all regions.')\n",
    "\n",
    "    # Save tables\n",
    "    tag_pt = safe_tag(pt)\n",
    "    pivot_path = OUT_TABLES / f'DS55_region_sector_pivot_{tag_pt}_{latest_year}.csv'\n",
    "    shares_path = OUT_TABLES / f'DS55_region_sector_shares_{tag_pt}_{latest_year}.csv'\n",
    "    class_path = OUT_TABLES / f'DS55_region_structure_classification_{tag_pt}_{latest_year}.csv'\n",
    "\n",
    "    pivot.reset_index().to_csv(pivot_path, index=False)\n",
    "    shares_table.reset_index().to_csv(shares_path, index=False)\n",
    "    class_df.to_csv(class_path, index=False)\n",
    "\n",
    "    all_outputs.extend([pivot_path, shares_path, class_path])\n",
    "\n",
    "    # Expected Output #3A: Stacked bar of shares\n",
    "    plot_df = shares_table.reset_index().merge(\n",
    "        pivot[['Total']].reset_index(), on='Region', how='left'\n",
    "    )\n",
    "    plot_df['Dominant_Sector'] = class_df.set_index('Region').loc[plot_df['Region'], 'Dominant_Sector'].values\n",
    "    dominant_order = pd.Categorical(plot_df['Dominant_Sector'], categories=['Agriculture', 'Industry', 'Services'], ordered=True)\n",
    "    plot_df = plot_df.assign(_dom_order=dominant_order).sort_values(['_dom_order', 'Total'], ascending=[True, False]).drop(columns=['_dom_order'])\n",
    "\n",
    "    x = np.arange(len(plot_df))\n",
    "    ag = plot_df['Share_Agri'].to_numpy()\n",
    "    ind = plot_df['Share_Industry'].to_numpy()\n",
    "    serv = plot_df['Share_Services'].to_numpy()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.bar(x, ag, label='Agriculture')\n",
    "    plt.bar(x, ind, bottom=ag, label='Industry')\n",
    "    plt.bar(x, serv, bottom=ag + ind, label='Services')\n",
    "    plt.title(f'Region x Sector Shares ({pt}, {latest_year})')\n",
    "    plt.xlabel('Region')\n",
    "    plt.ylabel('Share of Regional GRDP')\n",
    "    plt.xticks(x, plot_df['Region'], rotation=60, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_stack_path = OUT_FIGS / f'DS55_stacked_shares_{tag_pt}_{latest_year}.png'\n",
    "    plt.savefig(fig_stack_path, dpi=300)\n",
    "    plt.show()\n",
    "    all_outputs.append(fig_stack_path)\n",
    "\n",
    "    # Expected Output #3B: Heatmap of shares (optional, included)\n",
    "    heat_df = plot_df.set_index('Region')[['Share_Agri', 'Share_Industry', 'Share_Services']]\n",
    "\n",
    "    plt.figure(figsize=(8, max(6, len(heat_df) * 0.35)))\n",
    "    im = plt.imshow(heat_df.values, aspect='auto')\n",
    "    plt.colorbar(im, label='Share')\n",
    "    plt.title(f'Region x Sector Share Heatmap ({pt}, {latest_year})')\n",
    "    plt.xlabel('Sector')\n",
    "    plt.ylabel('Region')\n",
    "    plt.xticks(np.arange(3), ['Agriculture', 'Industry', 'Services'])\n",
    "    plt.yticks(np.arange(len(heat_df.index)), heat_df.index)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_heat_path = OUT_FIGS / f'DS55_heatmap_shares_{tag_pt}_{latest_year}.png'\n",
    "    plt.savefig(fig_heat_path, dpi=300)\n",
    "    plt.show()\n",
    "    all_outputs.append(fig_heat_path)\n",
    "\n",
    "    # Expected Output #4: concise interpretation inputs\n",
    "    dominant_counts = class_df['Dominant_Sector'].value_counts()\n",
    "    most_common_dom = dominant_counts.idxmax() if not dominant_counts.empty else 'N/A'\n",
    "\n",
    "    top_serv = class_df.nlargest(3, 'Share_Services')[['Region', 'Share_Services']]\n",
    "    top_ind = class_df.nlargest(3, 'Share_Industry')[['Region', 'Share_Industry']]\n",
    "    top_ag = class_df.nlargest(3, 'Share_Agri')[['Region', 'Share_Agri']]\n",
    "\n",
    "    diversified = class_df.nsmallest(3, 'Dominance_Gap')[['Region', 'Dominance_Gap']]\n",
    "    specialized = class_df.nlargest(3, 'Dominance_Gap')[['Region', 'Dominance_Gap']]\n",
    "\n",
    "    interpretation_rows.append({\n",
    "        'Price_Type': pt,\n",
    "        'Year': latest_year,\n",
    "        'Most_Common_Dominant_Sector': most_common_dom,\n",
    "        'Top3_Service_Heavy': '; '.join([f\"{r.Region} ({r.Share_Services:.3f})\" for r in top_serv.itertuples(index=False)]),\n",
    "        'Top3_Industry_Heavy': '; '.join([f\"{r.Region} ({r.Share_Industry:.3f})\" for r in top_ind.itertuples(index=False)]),\n",
    "        'Top3_Agriculture_Heavy': '; '.join([f\"{r.Region} ({r.Share_Agri:.3f})\" for r in top_ag.itertuples(index=False)]),\n",
    "        'Most_Diversified_3': '; '.join([f\"{r.Region} ({r.Dominance_Gap:.3f})\" for r in diversified.itertuples(index=False)]),\n",
    "        'Most_Specialized_3': '; '.join([f\"{r.Region} ({r.Dominance_Gap:.3f})\" for r in specialized.itertuples(index=False)])\n",
    "    })\n",
    "\n",
    "print('\\nSaved output files:', len(all_outputs))\n"
   ],
   "id": "efa93f094d120c5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation (concise, per Price_Type latest year)\n",
    "interp_df = pd.DataFrame(interpretation_rows)\n",
    "\n",
    "for row in interp_df.itertuples(index=False):\n",
    "    print(f\"\\nPrice_Type: {row.Price_Type} | Year: {row.Year}\")\n",
    "    print(f\"- Sector dominating most regions: {row.Most_Common_Dominant_Sector}\")\n",
    "    print(f\"- Top 3 most service-heavy regions: {row.Top3_Service_Heavy}\")\n",
    "    print(f\"- Top 3 most industry-heavy regions: {row.Top3_Industry_Heavy}\")\n",
    "    print(f\"- Top 3 most agriculture-heavy regions: {row.Top3_Agriculture_Heavy}\")\n",
    "    print(f\"- Most diversified regions (small dominance gap): {row.Most_Diversified_3}\")\n",
    "    print(f\"- Most specialized regions (large dominance gap): {row.Most_Specialized_3}\")\n"
   ],
   "id": "56069beceb98c88c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final quality check: ensure all expected outputs exist\n",
    "missing = [str(p) for p in all_outputs if not Path(p).exists()]\n",
    "\n",
    "if missing:\n",
    "    print('Missing outputs detected:')\n",
    "    for m in missing:\n",
    "        print('-', m)\n",
    "else:\n",
    "    print(f'All outputs exist. Count: {len(all_outputs)}')\n"
   ],
   "id": "3f7afa9c9757cb7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
