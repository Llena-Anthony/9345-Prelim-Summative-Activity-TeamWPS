{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BLOCK 0: Imports & Settings"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:42.560970200Z",
     "start_time": "2026-02-13T09:24:42.548712900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:42.922557900Z",
     "start_time": "2026-02-13T09:24:42.852266700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Files in CWD (first 30):\")\n",
    "for p in sorted(Path.cwd().glob(\"*\"))[:30]:\n",
    "    print(\" -\", p.name)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\02_Data_Preprocessing\n",
      "Files in CWD (first 30):\n",
      " - 01_data_preprocessing.ipynb\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BLOCK 1 — Robust project root & folders"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:43.243748800Z",
     "start_time": "2026-02-13T09:24:43.169779300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 1 — Robust Project Root + Paths\n",
    "# Finds the folder that contains \"01_Raw_Data\"\n",
    "# ==========================================================\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "while not (PROJECT_ROOT / \"01_Raw_Data\").exists():\n",
    "    if PROJECT_ROOT.parent == PROJECT_ROOT:\n",
    "        raise RuntimeError(\"Could not find PROJECT_ROOT (folder containing 01_Raw_Data).\")\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_ROOT = PROJECT_ROOT / \"01_Raw_Data\" / \"Gross Regional Domestic Product\"\n",
    "WITH_DIR = RAW_ROOT / \"By Industry (with NIR, 2025)\"\n",
    "WITHOUT_DIR = RAW_ROOT / \"By Industry (without NIR, 2021)\"\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"03_Cleaned_Data\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"WITH_DIR:\", WITH_DIR, \"| exists:\", WITH_DIR.exists())\n",
    "print(\"WITHOUT_DIR:\", WITHOUT_DIR, \"| exists:\", WITHOUT_DIR.exists())\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\n",
      "WITH_DIR: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (with NIR, 2025) | exists: True\n",
      "WITHOUT_DIR: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (without NIR, 2021) | exists: False\n",
      "OUT_DIR: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\03_Cleaned_Data\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 2: List Excel Files\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:43.536824800Z",
     "start_time": "2026-02-13T09:24:43.454756700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 1 — Robust Project Root + Paths\n",
    "# Finds the folder that contains \"01_Raw_Data\"\n",
    "# ==========================================================\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "while not (PROJECT_ROOT / \"01_Raw_Data\").exists():\n",
    "    if PROJECT_ROOT.parent == PROJECT_ROOT:\n",
    "        raise RuntimeError(\"Could not find PROJECT_ROOT (folder containing 01_Raw_Data).\")\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "RAW_ROOT = PROJECT_ROOT / \"01_Raw_Data\" / \"Gross Regional Domestic Product\"\n",
    "WITH_DIR = RAW_ROOT / \"By Industry (with NIR, 2025)\"\n",
    "# Auto-detect \"without NIR\" folder\n",
    "WITHOUT_DIR = next(\n",
    "    d for d in RAW_ROOT.iterdir()\n",
    "    if d.is_dir() and \"without\" in d.name.lower()\n",
    ")\n",
    "\n",
    "print(\"WITHOUT_DIR FOUND:\", WITHOUT_DIR)\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"03_Cleaned_Data\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"WITH_DIR:\", WITH_DIR, \"| exists:\", WITH_DIR.exists())\n",
    "print(\"WITHOUT_DIR:\", WITHOUT_DIR, \"| exists:\", WITHOUT_DIR.exists())\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT_DIR FOUND: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (without NIR, 2024)\n",
      "PROJECT_ROOT: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\n",
      "WITH_DIR: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (with NIR, 2025) | exists: True\n",
      "WITHOUT_DIR: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (without NIR, 2024) | exists: True\n",
      "OUT_DIR: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\03_Cleaned_Data\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 3: Text Cleaner"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:44.092876100Z",
     "start_time": "2026-02-13T09:24:44.075513800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 3 — Text Cleaning Utility\n",
    "# ==========================================================\n",
    "def clean_text(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).replace(\"\\u00a0\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 4: Header Detection"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:44.809841200Z",
     "start_time": "2026-02-13T09:24:44.793331800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 4 — Header Row Detection (PSA tables often start lower)\n",
    "# Detects a header row by:\n",
    "#  - keyword presence OR\n",
    "#  - many year cells in same row\n",
    "# ==========================================================\n",
    "HEADER_KEYWORDS = [\n",
    "    \"industry\", \"sector\", \"economic activity\",\n",
    "    \"kind of economic activity\", \"major industry\"\n",
    "]\n",
    "YEAR_CELL = re.compile(r\"^(19\\d{2}|20\\d{2})$\")\n",
    "\n",
    "def find_header_row(df_preview: pd.DataFrame, max_scan_rows=120) -> int | None:\n",
    "    for r in range(min(max_scan_rows, len(df_preview))):\n",
    "        row = df_preview.iloc[r].astype(str).fillna(\"\")\n",
    "        low = row.str.lower()\n",
    "\n",
    "        joined = \" | \".join(low.tolist())\n",
    "        if any(k in joined for k in HEADER_KEYWORDS):\n",
    "            return r\n",
    "\n",
    "        year_hits = sum(bool(YEAR_CELL.match(v.strip())) for v in row.tolist())\n",
    "        if year_hits >= 3:\n",
    "            return r\n",
    "\n",
    "    return None\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 5: Read best sheet"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:45.325987300Z",
     "start_time": "2026-02-13T09:24:45.309140400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 5 — Read Best Sheet from an Excel File\n",
    "# Tries each sheet, finds header row, then reads with that header.\n",
    "# ==========================================================\n",
    "def read_best_sheet(path: Path, preview_rows=80):\n",
    "    xls = pd.ExcelFile(path, engine=\"openpyxl\")\n",
    "\n",
    "    for sheet in xls.sheet_names:\n",
    "        prev = pd.read_excel(path, sheet_name=sheet, engine=\"openpyxl\", header=None, nrows=preview_rows)\n",
    "        hdr = find_header_row(prev)\n",
    "\n",
    "        if hdr is not None:\n",
    "            df = pd.read_excel(path, sheet_name=sheet, engine=\"openpyxl\", header=hdr)\n",
    "            df.columns = [clean_text(c) for c in df.columns]\n",
    "            df = df.dropna(axis=1, how=\"all\").copy()\n",
    "            return sheet, df\n",
    "\n",
    "    # fallback if nothing detected\n",
    "    df = pd.read_excel(path, sheet_name=0, engine=\"openpyxl\")\n",
    "    df.columns = [clean_text(c) for c in df.columns]\n",
    "    df = df.dropna(axis=1, how=\"all\").copy()\n",
    "    return xls.sheet_names[0], df\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 6: Infer Year + Price_Type from column header\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:45.828597700Z",
     "start_time": "2026-02-13T09:24:45.813147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 6 — Infer Year and Price_Type from column names\n",
    "# Works for headers like:\n",
    "#   \"At Current Prices 2000\"\n",
    "#   \"2000 At Constant 2018 Prices\"\n",
    "# ==========================================================\n",
    "YEAR_RE = re.compile(r\"(19\\d{2}|20\\d{2})\")\n",
    "\n",
    "def infer_year_and_price(col_name: str):\n",
    "    c = clean_text(col_name).lower()\n",
    "    year_match = YEAR_RE.search(c)\n",
    "    year = int(year_match.group(1)) if year_match else None\n",
    "\n",
    "    if \"current\" in c:\n",
    "        price_type = \"At Current Prices\"\n",
    "    elif \"constant\" in c:\n",
    "        price_type = \"At Constant 2018 Prices\"\n",
    "    else:\n",
    "        price_type = None\n",
    "\n",
    "    return year, price_type\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 7: Process ONE file into long format"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:46.341321Z",
     "start_time": "2026-02-13T09:24:46.311190900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_one_file(file_path: Path, regime_label: str) -> pd.DataFrame:\n",
    "    region_name = clean_text(file_path.stem.split(\",\")[0])\n",
    "\n",
    "    # --- read sheet raw (no header) ---\n",
    "    sheet, _ = read_best_sheet(file_path)  # reuse your sheet chooser\n",
    "    raw = pd.read_excel(file_path, sheet_name=sheet, engine=\"openpyxl\", header=None)\n",
    "\n",
    "    # --- find the row that contains BOTH \"At Current\" and \"At Constant\" (price header row) ---\n",
    "    def row_has_price_headers(row):\n",
    "        s = row.astype(str).str.lower().fillna(\"\")\n",
    "        joined = \" | \".join(s.tolist())\n",
    "        return (\"at current\" in joined) and (\"at constant\" in joined)\n",
    "\n",
    "    price_row = None\n",
    "    for r in range(min(60, len(raw))):\n",
    "        if row_has_price_headers(raw.iloc[r]):\n",
    "            price_row = r\n",
    "            break\n",
    "    if price_row is None:\n",
    "        raise ValueError(f\"Could not find price header row (sheet={sheet}, file={file_path.name}).\")\n",
    "\n",
    "    year_row = price_row + 1  # in your preview, years are directly below\n",
    "\n",
    "    # --- build column -> Price_Type map from the price_row ---\n",
    "    price_hdr = raw.iloc[price_row].astype(str).str.strip()\n",
    "    price_type_by_col = pd.Series(index=raw.columns, dtype=\"object\")\n",
    "\n",
    "    lower = price_hdr.str.lower()\n",
    "    price_type_by_col[lower.str.contains(\"at current\")] = \"At Current Prices\"\n",
    "    price_type_by_col[lower.str.contains(\"at constant\")] = \"At Constant 2018 Prices\"\n",
    "    price_type_by_col = price_type_by_col.ffill()  # fill across unnamed columns in each block\n",
    "\n",
    "    # --- build column -> Year map from year_row ---\n",
    "    years = raw.iloc[year_row]\n",
    "    year_by_col = pd.Series(index=raw.columns, dtype=\"float64\")\n",
    "    year_by_col[:] = pd.to_numeric(years, errors=\"coerce\")  # 2022, 2023, 2024...\n",
    "\n",
    "    # --- value columns are those that have BOTH a price type and a year ---\n",
    "    value_cols = [\n",
    "        c for c in raw.columns\n",
    "        if pd.notna(price_type_by_col.get(c)) and pd.notna(year_by_col.get(c))\n",
    "    ]\n",
    "    if len(value_cols) == 0:\n",
    "        raise ValueError(f\"No value columns found after mapping (sheet={sheet}, file={file_path.name}).\")\n",
    "\n",
    "    # --- industry rows start after year_row ---\n",
    "    data = raw.iloc[year_row + 1:].copy()\n",
    "\n",
    "    # first column that contains industry labels is the one where industries appear\n",
    "    # in your preview, industry text appears in column 0 (but sometimes it may shift)\n",
    "    # choose the column with the most non-null text entries\n",
    "    best_label_col = None\n",
    "    best_score = -1\n",
    "    for c in raw.columns[:3]:  # usually in first few cols\n",
    "        col = data[c].astype(str)\n",
    "        score = col.str.contains(r\"[A-Za-z]\", regex=True).sum()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_label_col = c\n",
    "\n",
    "    label_col = best_label_col if best_label_col is not None else 0\n",
    "    data = data.rename(columns={label_col: \"Industry\"})\n",
    "\n",
    "    data[\"Industry\"] = data[\"Industry\"].apply(clean_text)\n",
    "\n",
    "    # drop rows that are empty labels\n",
    "    data = data[data[\"Industry\"].notna() & (data[\"Industry\"] != \"\")].copy()\n",
    "\n",
    "    # --- clean leading dots like \"..Industry\" / \"....Manufacturing\" ---\n",
    "    data[\"Industry\"] = data[\"Industry\"].str.replace(r\"^\\.+\\s*\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # --- melt ---\n",
    "    long_df = data.melt(\n",
    "        id_vars=[\"Industry\"],\n",
    "        value_vars=value_cols,\n",
    "        var_name=\"col_id\",\n",
    "        value_name=\"GRDP\"\n",
    "    )\n",
    "\n",
    "    # attach Price_Type and Year from mapping\n",
    "    long_df[\"Price_Type\"] = long_df[\"col_id\"].map(price_type_by_col)\n",
    "    long_df[\"Year\"] = long_df[\"col_id\"].map(year_by_col).astype(\"Int64\")\n",
    "\n",
    "    # numeric cleanup\n",
    "    long_df[\"GRDP\"] = pd.to_numeric(\n",
    "        long_df[\"GRDP\"].astype(str).str.replace(\",\", \"\", regex=False),\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    long_df = long_df.dropna(subset=[\"GRDP\", \"Year\", \"Price_Type\", \"Industry\"]).copy()\n",
    "\n",
    "    # add metadata\n",
    "    long_df[\"Region\"] = region_name\n",
    "    long_df[\"GRDP_Regime\"] = regime_label\n",
    "    long_df[\"Source_File\"] = file_path.name\n",
    "\n",
    "    # final columns\n",
    "    long_df = long_df[[\"Region\", \"Industry\", \"Year\", \"Price_Type\", \"GRDP\", \"GRDP_Regime\", \"Source_File\"]].copy()\n",
    "\n",
    "    return long_df\n"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 8: Process an entire folder + write error logs to 03_Cleaned_Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:24:47.545207600Z",
     "start_time": "2026-02-13T09:24:47.529345400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 8 — Process Folder + Error Log\n",
    "# Saves errors to 03_Cleaned_Data so you can always find it.\n",
    "# ==========================================================\n",
    "def process_folder(folder: Path, regime_label: str, error_log_name: str) -> pd.DataFrame:\n",
    "    files = list_excel_files(folder)\n",
    "    print(f\"[INFO] {regime_label}: Found {len(files)} Excel files in {folder}\")\n",
    "\n",
    "    if len(files) == 0:\n",
    "        raise RuntimeError(f\"No Excel files found in {folder}\")\n",
    "\n",
    "    all_parts = []\n",
    "    errors = []\n",
    "\n",
    "    for fp in files:\n",
    "        try:\n",
    "            part = process_one_file(fp, regime_label)\n",
    "            all_parts.append(part)\n",
    "        except Exception as e:\n",
    "            errors.append({\"file\": fp.name, \"error\": repr(e)})\n",
    "\n",
    "    # Always write error log if anything failed\n",
    "    if errors:\n",
    "        err_df = pd.DataFrame(errors)\n",
    "        err_path = OUT_DIR / error_log_name\n",
    "        err_df.to_csv(err_path, index=False)\n",
    "        print(f\"[WARN] {len(errors)} files failed for {regime_label}. Logged to: {err_path}\")\n",
    "        print(err_df.head(5).to_string(index=False))\n",
    "\n",
    "    if not all_parts:\n",
    "        # Print one-file debug hint\n",
    "        print(\"\\n[DEBUG] Trying to inspect first file quickly...\")\n",
    "        sample = files[0]\n",
    "        print(\"Sample file:\", sample)\n",
    "        try:\n",
    "            sheet, df = read_best_sheet(sample)\n",
    "            print(\"Chosen sheet:\", sheet)\n",
    "            print(\"Columns:\", df.columns.tolist()[:20])\n",
    "            print(df.head(5).to_string(index=False))\n",
    "        except Exception as e:\n",
    "            print(\"Even sample debug failed:\", repr(e))\n",
    "\n",
    "        raise RuntimeError(f\"No files successfully processed in {folder.resolve()}\")\n",
    "\n",
    "    return pd.concat(all_parts, ignore_index=True)\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:25:52.888921800Z",
     "start_time": "2026-02-13T09:25:52.839405800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def list_excel_files(folder: Path) -> list[Path]:\n",
    "    folder = Path(folder)\n",
    "    files = []\n",
    "    files += list(folder.rglob(\"*.xlsx\"))\n",
    "    files += list(folder.rglob(\"*.xlsm\"))\n",
    "    files += list(folder.rglob(\"*.xls\"))   # safe addition\n",
    "    files = sorted(set(files), key=lambda p: p.name.lower())\n",
    "    return [f for f in files if f.is_file()]\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 9: Run ingestion (creates combined long table)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:25:57.189358300Z",
     "start_time": "2026-02-13T09:25:54.695904800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 9 — RUN INGESTION\n",
    "# ==========================================================\n",
    "with_long = process_folder(WITH_DIR, \"With NIR\", \"_preprocessing_errors_with_nir.csv\")\n",
    "without_long = process_folder(WITHOUT_DIR, \"Without NIR\", \"_preprocessing_errors_without_nir.csv\")\n",
    "\n",
    "combined = pd.concat([with_long, without_long], ignore_index=True)\n",
    "\n",
    "print(\"combined shape:\", combined.shape)\n",
    "print(\"Price types:\\n\", combined[\"Price_Type\"].value_counts())\n",
    "print(\"Year range:\", combined[\"Year\"].min(), \"to\", combined[\"Year\"].max())\n",
    "combined.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] With NIR: Found 16 Excel files in C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (with NIR, 2025)\n",
      "[INFO] Without NIR: Found 15 Excel files in C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\01_Raw_Data\\Gross Regional Domestic Product\\By Industry (without NIR, 2024)\n",
      "combined shape: (15504, 7)\n",
      "Price types:\n",
      " Price_Type\n",
      "At Current Prices          7752\n",
      "At Constant 2018 Prices    7752\n",
      "Name: count, dtype: int64\n",
      "Year range: 2000 to 2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         Region                                        Industry  Year  \\\n",
       "0  Bicol Region              Agriculture, forestry, and fishing  2022   \n",
       "1  Bicol Region                                        Industry  2022   \n",
       "2  Bicol Region                            Mining and quarrying  2022   \n",
       "3  Bicol Region                                   Manufacturing  2022   \n",
       "4  Bicol Region  Electricity, steam, water and waste management  2022   \n",
       "\n",
       "          Price_Type         GRDP GRDP_Regime  \\\n",
       "0  At Current Prices  100710958.0    With NIR   \n",
       "1  At Current Prices  222926775.0    With NIR   \n",
       "2  At Current Prices   13179419.0    With NIR   \n",
       "3  At Current Prices   43289696.0    With NIR   \n",
       "4  At Current Prices   38587933.0    With NIR   \n",
       "\n",
       "                                         Source_File  \n",
       "0  Bicol Region, Gross Regional Domestic Product,...  \n",
       "1  Bicol Region, Gross Regional Domestic Product,...  \n",
       "2  Bicol Region, Gross Regional Domestic Product,...  \n",
       "3  Bicol Region, Gross Regional Domestic Product,...  \n",
       "4  Bicol Region, Gross Regional Domestic Product,...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Year</th>\n",
       "      <th>Price_Type</th>\n",
       "      <th>GRDP</th>\n",
       "      <th>GRDP_Regime</th>\n",
       "      <th>Source_File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bicol Region</td>\n",
       "      <td>Agriculture, forestry, and fishing</td>\n",
       "      <td>2022</td>\n",
       "      <td>At Current Prices</td>\n",
       "      <td>100710958.0</td>\n",
       "      <td>With NIR</td>\n",
       "      <td>Bicol Region, Gross Regional Domestic Product,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bicol Region</td>\n",
       "      <td>Industry</td>\n",
       "      <td>2022</td>\n",
       "      <td>At Current Prices</td>\n",
       "      <td>222926775.0</td>\n",
       "      <td>With NIR</td>\n",
       "      <td>Bicol Region, Gross Regional Domestic Product,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bicol Region</td>\n",
       "      <td>Mining and quarrying</td>\n",
       "      <td>2022</td>\n",
       "      <td>At Current Prices</td>\n",
       "      <td>13179419.0</td>\n",
       "      <td>With NIR</td>\n",
       "      <td>Bicol Region, Gross Regional Domestic Product,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bicol Region</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>2022</td>\n",
       "      <td>At Current Prices</td>\n",
       "      <td>43289696.0</td>\n",
       "      <td>With NIR</td>\n",
       "      <td>Bicol Region, Gross Regional Domestic Product,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bicol Region</td>\n",
       "      <td>Electricity, steam, water and waste management</td>\n",
       "      <td>2022</td>\n",
       "      <td>At Current Prices</td>\n",
       "      <td>38587933.0</td>\n",
       "      <td>With NIR</td>\n",
       "      <td>Bicol Region, Gross Regional Domestic Product,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Block 9.1: Quick sanity checks (make sure data is valid)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:26:00.273466400Z",
     "start_time": "2026-02-13T09:26:00.156473100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 9.1 — Sanity Checks (combined long table)\n",
    "# ==========================================================\n",
    "print(\"WITH rows:\", len(with_long))\n",
    "print(\"WITHOUT rows:\", len(without_long))\n",
    "print(\"COMBINED rows:\", len(combined))\n",
    "\n",
    "print(\"\\nPrice_Type distribution:\")\n",
    "print(combined[\"Price_Type\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nYear range:\", combined[\"Year\"].min(), \"to\", combined[\"Year\"].max())\n",
    "\n",
    "print(\"\\nSample rows:\")\n",
    "display(combined.head(10)) if \"display\" in globals() else print(combined.head(10).to_string(index=False))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH rows: 1824\n",
      "WITHOUT rows: 13680\n",
      "COMBINED rows: 15504\n",
      "\n",
      "Price_Type distribution:\n",
      "Price_Type\n",
      "At Current Prices          7752\n",
      "At Constant 2018 Prices    7752\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Year range: 2000 to 2024\n",
      "\n",
      "Sample rows:\n",
      "      Region                                                             Industry  Year        Price_Type        GRDP GRDP_Regime                                                     Source_File\n",
      "Bicol Region                                   Agriculture, forestry, and fishing  2022 At Current Prices 100710958.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                                                             Industry  2022 At Current Prices 222926775.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                                                 Mining and quarrying  2022 At Current Prices  13179419.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                                                        Manufacturing  2022 At Current Prices  43289696.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                       Electricity, steam, water and waste management  2022 At Current Prices  38587933.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                                                         Construction  2022 At Current Prices 127869728.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                                                             Services  2022 At Current Prices 322144021.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region Wholesale and retail trade; repair of motor vehicles and motorcycles  2022 At Current Prices  81584879.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                                           Transportation and storage  2022 At Current Prices  31727929.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n",
      "Bicol Region                            Accommodation and food service activities  2022 At Current Prices  12507439.0    With NIR Bicol Region, Gross Regional Domestic Product, by Industry.xlsm\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Block 9.2: Clean \"Industry\" Labels"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:26:01.948953500Z",
     "start_time": "2026-02-13T09:26:01.890446900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 9.2 — Clean Industry Labels\n",
    "# ==========================================================\n",
    "combined[\"Industry\"] = combined[\"Industry\"].astype(str).str.strip()\n",
    "combined[\"Industry\"] = combined[\"Industry\"].str.replace(r\"^\\.+\\s*\", \"\", regex=True)\n",
    "combined[\"Industry\"] = combined[\"Industry\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Remove obvious blanks\n",
    "combined = combined[combined[\"Industry\"].notna() & (combined[\"Industry\"] != \"\")].copy()\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Dataset 1 / 2 / 3 (CLEANED)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:26:03.029175Z",
     "start_time": "2026-02-13T09:26:02.930719500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 10 — Build Dataset 1/2/3 (CLEANED)\n",
    "# ==========================================================\n",
    "\n",
    "def map_main_sector(industry: str):\n",
    "    s = str(industry).lower().strip()\n",
    "\n",
    "    if s == \"gross domestic product\":\n",
    "        return \"Gross Domestic Product\"\n",
    "    if \"agriculture\" in s and (\"forestry\" in s or \"fishing\" in s or \"agriculture\" in s):\n",
    "        return \"Agriculture, forestry, and fishing\"\n",
    "    if s == \"industry\" or s.endswith(\"industry\"):\n",
    "        return \"Industry\"\n",
    "    if s == \"services\" or s.endswith(\"services\"):\n",
    "        return \"Services\"\n",
    "    return None\n",
    "\n",
    "combined[\"Main_Sector\"] = combined[\"Industry\"].apply(map_main_sector)\n",
    "\n",
    "# --------------------------\n",
    "# Dataset 3\n",
    "# --------------------------\n",
    "df3 = (\n",
    "    combined[combined[\"Main_Sector\"].notna()].copy()\n",
    "    .groupby([\"Region\", \"Main_Sector\", \"Year\", \"Price_Type\"], as_index=False)[\"GRDP\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"GRDP\": \"Sector_GRDP\"})\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Dataset 2 (exclude GDP total)\n",
    "# --------------------------\n",
    "df2 = (\n",
    "    df3[df3[\"Main_Sector\"].ne(\"Gross Domestic Product\")].copy()\n",
    "    .groupby([\"Main_Sector\", \"Year\", \"Price_Type\"], as_index=False)[\"Sector_GRDP\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"Sector_GRDP\": \"Total_GRDP\"})\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Dataset 1 (prefer GDP total row if present)\n",
    "# --------------------------\n",
    "gdp_rows = combined[combined[\"Industry\"].astype(str).str.strip().eq(\"Gross Domestic Product\")].copy()\n",
    "\n",
    "if len(gdp_rows) > 0:\n",
    "    df1 = (\n",
    "        gdp_rows.groupby([\"Region\", \"Year\", \"Price_Type\"], as_index=False)[\"GRDP\"]\n",
    "        .sum()\n",
    "        .rename(columns={\"GRDP\": \"Total_GRDP\"})\n",
    "    )\n",
    "else:\n",
    "    df1 = (\n",
    "        df3[df3[\"Main_Sector\"].ne(\"Gross Domestic Product\")].copy()\n",
    "        .groupby([\"Region\", \"Year\", \"Price_Type\"], as_index=False)[\"Sector_GRDP\"]\n",
    "        .sum()\n",
    "        .rename(columns={\"Sector_GRDP\": \"Total_GRDP\"})\n",
    "    )\n",
    "\n",
    "print(\"DF1 shape:\", df1.shape)\n",
    "print(\"DF2 shape:\", df2.shape)\n",
    "print(\"DF3 shape:\", df3.shape)\n",
    "\n",
    "print(\"\\nDF1 Price_Type:\")\n",
    "print(df1[\"Price_Type\"].value_counts())\n",
    "\n",
    "print(\"\\nDF2 Main_Sector:\")\n",
    "print(df2[\"Main_Sector\"].value_counts())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF1 shape: (760, 4)\n",
      "DF2 shape: (150, 4)\n",
      "DF3 shape: (3040, 5)\n",
      "\n",
      "DF1 Price_Type:\n",
      "Price_Type\n",
      "At Constant 2018 Prices    380\n",
      "At Current Prices          380\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DF2 Main_Sector:\n",
      "Main_Sector\n",
      "Agriculture, forestry, and fishing    50\n",
      "Industry                              50\n",
      "Services                              50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Block 10.1: Validate that Dataset 2 has NO \"Gross Domestic Product\""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:20:16.168232500Z",
     "start_time": "2026-02-13T09:20:16.142213400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 10.1 — Validate Dataset 2 (must not include GDP total)\n",
    "# ==========================================================\n",
    "assert \"Gross Domestic Product\" not in df2[\"Main_Sector\"].unique()\n",
    "print(\"✅ Dataset 2 is clean (no GDP total row).\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 2 is clean (no GDP total row).\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:20:16.253590Z",
     "start_time": "2026-02-13T09:20:16.175231800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 11 — Save Outputs (CLEANED CSVs)\n",
    "# ==========================================================\n",
    "df1.to_csv(OUT_DIR / \"Dataset 1 Regional_Economic_Magnitude (CLEANED).csv\", index=False)\n",
    "df2.to_csv(OUT_DIR / \"Dataset 2 Sector_Economic_Structure (CLEANED).csv\", index=False)\n",
    "df3.to_csv(OUT_DIR / \"Dataset 3 Region_Sector_Structure (CLEANED).csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved to:\", OUT_DIR)\n",
    "print(\" - Dataset 1 Regional_Economic_Magnitude (CLEANED).csv\")\n",
    "print(\" - Dataset 2 Sector_Economic_Structure (CLEANED).csv\")\n",
    "print(\" - Dataset 3 Region_Sector_Structure (CLEANED).csv\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to: C:\\Users\\Anthony Llena\\OneDrive\\Documents\\SLU\\DATA SCI PRELIMS\\9345-Prelim-Summative-Activity-TeamWPS\\03_Cleaned_Data\n",
      " - Dataset 1 Regional_Economic_Magnitude (CLEANED).csv\n",
      " - Dataset 2 Sector_Economic_Structure (CLEANED).csv\n",
      " - Dataset 3 Region_Sector_Structure (CLEANED).csv\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:20:16.337906800Z",
     "start_time": "2026-02-13T09:20:16.277596800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# BLOCK 12 — Final Quick Checks\n",
    "# ==========================================================\n",
    "print(\"\\nDF1 preview:\")\n",
    "print(df1.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nDF2 preview:\")\n",
    "print(df2.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nDF3 preview:\")\n",
    "print(df3.head(5).to_string(index=False))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF1 preview:\n",
      "                                         Region  Year              Price_Type  Total_GRDP\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao  2000 At Constant 2018 Prices  98017851.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao  2000       At Current Prices  45671649.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao  2001 At Constant 2018 Prices  94136902.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao  2001       At Current Prices  44751362.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao  2002 At Constant 2018 Prices 105745055.0\n",
      "\n",
      "DF2 preview:\n",
      "                       Main_Sector  Year              Price_Type   Total_GRDP\n",
      "Agriculture, forestry, and fishing  2000 At Constant 2018 Prices 1045259507.0\n",
      "Agriculture, forestry, and fishing  2000       At Current Prices  505134510.0\n",
      "Agriculture, forestry, and fishing  2001 At Constant 2018 Prices 1084420004.0\n",
      "Agriculture, forestry, and fishing  2001       At Current Prices  525368838.0\n",
      "Agriculture, forestry, and fishing  2002 At Constant 2018 Prices 1125200404.0\n",
      "\n",
      "DF3 preview:\n",
      "                                         Region                        Main_Sector  Year              Price_Type  Sector_GRDP\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao Agriculture, forestry, and fishing  2000 At Constant 2018 Prices   55373996.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao Agriculture, forestry, and fishing  2000       At Current Prices   23764098.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao Agriculture, forestry, and fishing  2001 At Constant 2018 Prices   50753557.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao Agriculture, forestry, and fishing  2001       At Current Prices   20362653.0\n",
      "Bangsamoro Autonomous Region in Muslim Mindanao Agriculture, forestry, and fishing  2002 At Constant 2018 Prices   58042444.0\n"
     ]
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:20:16.565924300Z",
     "start_time": "2026-02-13T09:20:16.513544100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regions = sorted(combined[\"Region\"].dropna().unique())\n",
    "print(\"Total regions:\", len(regions))\n",
    "print(\"Regions (sample):\", regions[:30])\n",
    "\n",
    "# search for likely BARMM strings\n",
    "hits = [r for r in regions if \"barmm\" in r.lower() or \"bangsamoro\" in r.lower() or \"muslim mindanao\" in r.lower()]\n",
    "print(\"BARMM-like hits:\", hits)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total regions: 18\n",
      "Regions (sample): ['Bangsamoro Autonomous Region in Muslim Mindanao', 'Bicol Region', 'CALABARZON', 'Cagayan Valley', 'Caraga', 'Central Luzon', 'Central Visayas', 'Cordillera Administrative Region', 'Davao Region', 'Eastern Visayas', 'Ilocos Region', 'MIMAROPA', 'MIMAROPA Region', 'National Capital Region', 'Northern Mindanao', 'SOCCSKSARGEN', 'Western Visayas', 'Zamboanga Peninsula']\n",
      "BARMM-like hits: ['Bangsamoro Autonomous Region in Muslim Mindanao']\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:20:17.059521500Z",
     "start_time": "2026-02-13T09:20:17.012528600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = list_excel_files(WITH_DIR)\n",
    "print(\"Total files:\", len(files))\n",
    "\n",
    "barmm_files = [\n",
    "    f.name for f in files\n",
    "    if (\"barmm\" in f.name.lower())\n",
    "    or (\"bangsamoro\" in f.name.lower())\n",
    "    or (\"armm\" in f.name.lower())\n",
    "    or (\"muslim mindanao\" in f.name.lower())\n",
    "]\n",
    "\n",
    "print(\"BARMM-like files:\", barmm_files)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 17\n",
      "BARMM-like files: ['Bangsamoro Autonomous Region in Muslim Mindanao, Gross Regional Domestic Product, by Industry.xlsm']\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T09:20:17.642257800Z",
     "start_time": "2026-02-13T09:20:17.607355400Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
